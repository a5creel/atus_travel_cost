---
title: "RUM Model: welfare calcs"
author: "Andie Creel"
date: "2023-07-06"
output: 
  pdf_document:
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message  = FALSE)
```

# Question of interest: 

How could the ATUS data set produce an easily repeatable statistical product evaluating the contribution of local outdoor recreation to American's welfare.
  
# RUM model (Annual)

Indirect utility (simplest model possible):

$$V_{itc} = \alpha_c + \beta x_{ic} $$
Where $V$ is the indirect utility for person $i$ on choice occasion $t$ (day) for choice $c$. $\alpha$ is a choice specific constant. $\beta$ is a general coefficient for travel **time** $x$. 


```{r}
rm(list = ls())
options(scipen = 999)
library(dplyr)
library(tidyr)
library(stringr)
library(vroom)
library(mlogit)
library(stargazer)
library(lubridate)
library(ggplot2)
library(gridExtra)
library(parallel)
library(urbnmapr) # For map


# -----------------------------------------------------------------------------
# read in R memory built in R_data_objs
# -----------------------------------------------------------------------------
load("05.RUM_data_objs.RData")

# -----------------------------------------------------------------------------
# preferred reg specification (total travel time grouped by state)
# -----------------------------------------------------------------------------

# income not included and temp
reg1 <- mlogit(choice ~ travel_time_total_state, 
               myRUM_idx, 
               reflevel = "indoor_home") 

# temp included 
reg2 <- mlogit(choice ~ travel_time_total_state | tmmx, 
               myRUM_idx, 
               reflevel = "indoor_home")

stargazer(reg1, reg2, 
          title = "preferred model (entire year)",
          type = "text")

```
 The numeraire is minutes. 
 
Currently dropping so much data for where I don't have temperature data. Including temperature is important for the intercepts, but has little effect on the dis-utility from travel, $\beta$. 

### Map 

```{r}
# -----------------------------------------------------------------------------
# Map for all counties 
# -----------------------------------------------------------------------------

# code if temperature is NA 
myCounties_1 <- myRUM_df %>%
  select(county, tmmx) %>%
  mutate(value = if_else(!is.na(tmmx), "has temp data", "no temp data")) %>% 
  select(-tmmx) %>% 
  distinct() %>% 
  filter(county %% 1000 != 0)
  
counties_sf_og <- get_urbn_map(map = "counties", sf = TRUE)

counties_sf <- counties_sf_og %>%
  mutate(county_fips = as.numeric(county_fips))

myMap_1_df <- left_join(counties_sf, myCounties_1, by =c("county_fips" = "county"))

myMap_1_df %>%
  ggplot() +
  geom_sf(mapping = aes(fill = factor(value)), color = NA) +  # Use factor to treat value as discrete
  geom_sf(data = counties_sf_og, fill = NA, color = "black", size = 0.25) +
  coord_sf(datum = NA) +   
  scale_fill_manual(values = c("no temp data" = "red", "has temp data" = "blue"), na.value = "white") +
  theme_bw() + theme(legend.position = "bottom", panel.border = element_blank()) +
  ggtitle("Counties that I currently have ATUS data for")



```

When I drop data for counties that I don't have temperate data for, only drop 4 counties (all in AK or HI). The lack of temperate data isn't systematic in a region, the issue is seems to be that around half of people don't report what county they live in, they only report the state that they live in. 

I investigated if this was an issue of merging on county versus MSA, but that doesn't fix it either. 



# Welfare calcs

We can identify consumer surplus up to an unidentified constant, therefore the number on its own is not relevant. However changes in consumer surplus are identified. 

I can use a log-sum to calculate the expected utility for each choice occasion, t,  

$$E(U_t) = \ln \sum_{c = 1}^C e^{V_{tc}} + C.$$

If I know that marginal utility of the numeraire, $\beta$, then I can calculate the expected consumer surplus, $\frac{E(U)}{\beta}$. 

## Potential Counterfactuals


### No travel time to outdoor leisure >10 min 

A major goal that originated at Trust for Public Land and has been talked about for 30x30 is to have a green space within 10 minutes of anyone (? I need to double check all this).

In this counter factual I change any travel time great than 10 minutes to 10 minutes. 

```{r}
# -----------------------------------------------------------------------------
# calculate inclusive value for baseline
# -----------------------------------------------------------------------------
iv_baseline <- logsum(reg1)

# -----------------------------------------------------------------------------
# create a data set where travel time isn't ever more than 10 minutes for outdoor leisure
# -----------------------------------------------------------------------------

myRUM_10min <- myRUM_df %>%
  select(choice, travel_time_total_state, tmmx, activity) %>% 
  mutate(travel_time_total_state = if_else(activity == "outdoor_away" & travel_time_total_state > 10, 
                                           10, travel_time_total_state)) %>% 
  dfidx(idx = list(NA, "activity")) 

# calc indirect utility for everyone under new scenario 
iv_10min <- logsum(reg1, data = myRUM_10min)

# calculate change in welfare
surplus_10min <- - (iv_10min - iv_baseline) / coef(reg1)["travel_time_total_state"] 
summary(surplus_10min)



```


Expected consumer's surplus variation range from 0 to 19 minutes, with a median value of about 1 minute. This is per choice occasion (day). 

ATTN: Does this account for how many people would start taking a trip who hadn't been earlier? *I believe it does, but want to discuss.* 


### Travel time for ourdoor rec goes to infinity 

Sending the price to infinity is semi-commonly used (to various degrees of acceptance) to simulate the welfare loss of eliminating a choice. This could potentially be used to get the total welfare contribution of that choice existing. 

If the goal is to create a easily repeatable statistical product *that measures the welfare contribution of an activity annually* I believe this would be the most established way to achieve that goal. 

```{r}
# -----------------------------------------------------------------------------
# create a data set where travel time goes to infinity 
# -----------------------------------------------------------------------------

myRUM_inf <- myRUM_df %>%
  select(choice, travel_time_total_state, tmmx, activity) %>% 
  mutate(travel_time_total_state = if_else(activity == "outdoor_away" , 10^4, travel_time_total_state)) %>% 
  dfidx(idx = list(NA, "activity")) 

# calc indirect utility for everyone under new scenario 
iv_inf <- logsum(reg1, data = myRUM_inf)

# calculate change in welfare
surplus_inf <- - (iv_inf - iv_baseline) / coef(reg1)["travel_time_total_state"] 
summary(surplus_inf)


```


If the travel cost of visiting a park went to 10,000 minutes (if I go an order of magnitude beyond this I get hessian errors), the average person would experience 16 minutes of welfare loss per choice occasion. I tried with 40K and got same result. 

This is per choice occasion. So this would be 97 hours per person per year (16*365/60).

Median weekly income in Q2 2023 is \$1,095, or \$27 per hour assuming a 40 hour work week. This would be a welfare loss of \$2628 per year per person.


# Trend through years

```{r}

getAnnualCS <- function(y){
  
  # --------------------------------------------
  #  calc baseline for that year 
  # --------------------------------------------
  
  # get annual df by filtering on year
  myRUM_og <- myRUM_df %>%
    select(choice, travel_time_total_state, tmmx, activity, year) %>% 
    filter(year == y) %>% 
    dfidx(idx = list(NA, "activity"))
    
  #rerun regression 
  reg_og <- mlogit(choice ~ travel_time_total_state , 
               myRUM_og, 
               reflevel = "indoor_home") 

  # calc indirect utility for everyone under new scenario 
  iv_og <- logsum(reg_og)
  
  # --------------------------------------------
  #  calc if price of parks went in 10^4 which mimics infinity
  # --------------------------------------------
  myRUM_inf <- myRUM_df %>%
    select(choice, travel_time_total_state, tmmx, activity, year) %>% 
    mutate(travel_time_total_state = if_else(activity == "outdoor_away" , 10^4, travel_time_total_state)) %>%
    filter(year == y) %>% 
    dfidx(idx = list(NA, "activity"))
  
  # calc indirect utility for everyone under new scenario 
  iv_inf <- logsum(reg_og, data = myRUM_inf)

  
  # calculate change in welfare
  surplus <- - (iv_inf - iv_og) / coef(reg_og)["travel_time_total_state"] 
  
  return(summary(surplus))
  # return(coef(reg_og)["travel_time_total_state"])
}

myCS_inf_03_21 <- mclapply(2003:2021, getAnnualCS) %>%
  bind_rows() %>%
  bind_cols(year = 2003:2021) %>%
  select(year, everything())

mean(myCS_inf_03_21$Mean) # checks out as 16 (to be expected)

# Plotting trend
ggplot(myCS_inf_03_21, aes(x = year, y = Mean)) +
  geom_point() +
  geom_smooth(method = "lm", se = F) + 
  labs(x = "Year", y = "Consumer Surplus (minutes)") +
  ggtitle("Change in Consumer Surplus", subtitle = "For if the travel cost of outdoor rec went to 10K minutes") +
  theme_bw()



```


This is really throwing me because some previous graphs made it look like recreation time was increasing, but here I'm getting that the welfare has gone down through time. Those previous graphs were on the extensive margin.

The trend line is very steep down, but it seems like it's actually been pretty stable since 2010. 

What I'm wondering is if this is people become more inelastic to a price change? Investigate this, but at first glance that doesn't seem like it. 

Thing to think about with the time trend is that supply of local recreation locations has changed over time and so more people may be able to travel less? I need to think about the different mechanisms that could lead to this result. 

### Number of Americans that choose each activity per day 

```{r}
# -----------------------------------------------------------------------------
# Pivot back wide
# -----------------------------------------------------------------------------

myRUM_wide <- myRUM_df %>% 
  pivot_wider(
    id_cols = c(caseid, date),
    names_from = activity,
    values_from = c(number_activities, travel_time_avg_race, travel_time_total_race,
                    travel_time_avg_state, travel_time_total_state, choice)
  )

# -----------------------------------------------------------------------------
# Multiply by weight
# -----------------------------------------------------------------------------

myDems <- vroom("clean_data/2.demographics_ALL.csv")

myRUM_wide_wts <- left_join(myRUM_wide, myDems, by = "caseid") 

myAvgChoicePerDay <- myRUM_wide_wts %>% 
  select(date,starts_with("choice"), wt, year) %>% 
  
  # multiply if someone did an activity by that person's weight 
  mutate(wt_outdoor_away = wt*choice_outdoor_away) %>% 
  mutate(wt_indoor_away = wt*choice_indoor_away) %>%
  mutate(wt_indoor_home = wt*choice_indoor_home) %>%
  mutate(wt_outdoor_home = wt*choice_outdoor_home) %>% 
  select(date, year, starts_with("wt_")) %>% 
  
  #get total people by day
  group_by(date) %>% 
  mutate(
    sum_outdoor_away = sum(wt_outdoor_away, na.rm = FALSE),
    sum_indoor_away = sum(wt_indoor_away, na.rm = FALSE),
    sum_indoor_home = sum(wt_indoor_home, na.rm = FALSE),
    sum_outdoor_home = sum(wt_outdoor_home, na.rm = FALSE)) %>% 
  ungroup %>% 
  
  # get average trips per day by year
  group_by(year) %>% 
   summarise(
    mean_outdoor_away = mean(sum_outdoor_away, na.rm = FALSE),
    mean_indoor_away =  mean(sum_indoor_away, na.rm = FALSE),
    mean_indoor_home =  mean(sum_indoor_home, na.rm = FALSE),
    mean_outdoor_home = mean(sum_outdoor_home, na.rm = FALSE)) %>% 
  pivot_longer(
    cols = starts_with("mean_"),
    names_to = "variable",
    values_to = "value"
  )

# plot indoor
myAvgChoicePerDay_indoor <- myAvgChoicePerDay %>% 
  filter(str_detect(variable, "indoor"))

num_per_day_in <- ggplot(myAvgChoicePerDay_indoor , aes(x = year, y = value, color = variable)) +
  geom_line() +
  labs(title = "Total trips per day (Indoor)",
       x = "Year",
       y = "Trips") +
  theme_bw()
  
# plot outdoor
myAvgChoicePerDay_outdoor <- myAvgChoicePerDay %>% 
  filter(str_detect(variable, "outdoor"))

num_per_day_out <- ggplot(myAvgChoicePerDay_outdoor , aes(x = year, y = value, color = variable)) +
  geom_line() +
  labs(title = "Total trips per day (Outdoor)",
       x = "Year",
       y = "Trips") +
  theme_bw()


grid.arrange(num_per_day_in, num_per_day_out)

```

### Welfare per day multiplied by expected number of trips per year 

```{r}
# -----------------------------------------------------------------------------
# merge mean num trips with suprlus per day 
# -----------------------------------------------------------------------------

# trips per day 
myTripsPerYear_outdoor <- myAvgChoicePerDay_outdoor %>% 
  filter(variable == "mean_outdoor_away") %>% 
  rename(trips_per_day = value) 

# value per day (numeraire is hours)
myCS_outdoor <- myCS_inf_03_21 %>% 
  select(year, Mean) %>% 
  rename(mean_cs_per_day_per_person = Mean)

# total CS per year 
myTotalWelfare_outdoor_og <- left_join(myTripsPerYear_outdoor, myCS_outdoor, by = "year") %>% 
  mutate(mean_cs_per_day_total = mean_cs_per_day_per_person * trips_per_day) %>% 
  mutate(mean_cs_per_year_hours = mean_cs_per_day_total * 365 / 60) # numeraire is hours


myTotalWelfare_outdoor <- myTotalWelfare_outdoor_og %>% 
  select(year, mean_cs_per_year_hours) %>% 
  mutate(mean_cs_per_year_dollars = mean_cs_per_year_hours * 27) # using median income's hourly (assuming 40 hour work week)

# Plotting trend
ggplot(myTotalWelfare_outdoor, aes(x = year, y = mean_cs_per_year_dollars/10^9)) +
  geom_point() +
  geom_smooth(method = "lm", se = F) + 
  labs(x = "Year", y = "Consumer Surplus (Billion dollars)") +
  ggtitle("Change in Consumer Surplus per Year", subtitle = "For if the travel cost of outdoor rec went to 10K minutes") +
  theme_bw()


```

Getting rid of local outdoor rec opportunities (away from home) would eliminate 30 billion dollars of consumer surplus per year. 


### average travel time to leisure activities 

```{r}

myTravelTimes_outdoor <- myRUM_wide %>% 
  filter(choice_outdoor_away == 1) %>%  # must participate in outdoor rec
  mutate(year = year(date)) %>% 
  select(year, travel_time_total_state_outdoor_away) 
  
# summary 
summary(myTravelTimes_outdoor$travel_time_total_state_outdoor_away)
  
# trend through time
myAvg_TravelTimes_outdoor <- myTravelTimes_outdoor %>% 
  mutate(avg_travel_time_03_21 = mean(travel_time_total_state_outdoor_away)) %>% 
  group_by(year) %>% 
  mutate(avg_travel_time_year = mean(travel_time_total_state_outdoor_away)) %>% 
  select(year, avg_travel_time_03_21, avg_travel_time_year) %>% 
  distinct()
  

# Plotting trend
ggplot(myAvg_TravelTimes_outdoor, aes(x = year, y = avg_travel_time_year)) +
  geom_point() +
  geom_smooth(method = "lm", se = F) + 
  labs(x = "Year", y = "Travel Time (minutes)") +
  ggtitle("Average travel time for away from home outdoor leisure") +
  theme_bw()



```

The average travel time for outdoor rec away from home is 12 minutes. A lot of people dont report traveling for outdoor rec despite reporting that they do participate in it. 

The travel time for outdoor rec seems to be trending down. If travel time are getting shorter that coudl explain CS decreasing when using a travel cost methodology. 















